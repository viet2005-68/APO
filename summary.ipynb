{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb75f5fa",
   "metadata": {},
   "source": [
    "## Exemplar Optimization via Genetic Search\n",
    "\n",
    "We augment the original prompt optimization pipeline with an explicit exemplar optimization step, where the goal is to select a set of exemplars that maximizes task performance while controlling prompt length and redundancy among exemplars.\n",
    "\n",
    "---\n",
    "\n",
    "### Error-Weighted Exemplar Sampling with Temperature\n",
    "\n",
    "To guide exemplar selection toward informative training examples while retaining exploration, we introduce an error-weighted sampling mechanism based on temperature-scaled softmax.\n",
    "\n",
    "Let $c_i$ denote the accumulated error count for training example $e_i$. We define a sampling distribution over the training set as:\n",
    "\n",
    "$$\n",
    "P(e_i)\n",
    "=\n",
    "\\frac{\n",
    "\\exp\\left( \\frac{c_i}{T} \\right)\n",
    "}{\n",
    "\\sum_j \\exp\\left( \\frac{c_j}{T} \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "where \\(T > 0\\) is a temperature parameter controlling the entropy of the distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### Effect of Temperature\n",
    "\n",
    "- Large \\(T\\) produces a near-uniform distribution, encouraging exploration.\n",
    "- Small \\(T\\) sharpens the distribution, concentrating probability mass on high-error examples.\n",
    "\n",
    "In the limit:\n",
    "\n",
    "$$\n",
    "T \\to \\infty: \\quad P(e_i) \\approx \\frac{1}{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "T \\to 0: \\quad P(e_i) \\text{ collapses to the highest-error example}\n",
    "$$\n",
    "\n",
    "\n",
    "This behavior mirrors temperature-scaled sampling in large language models, where temperature modulates randomness in token selection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1a0b",
   "metadata": {},
   "source": [
    "### Ojective Function\n",
    "\n",
    "$$\n",
    "\\text{score}\n",
    "=\n",
    "m\\!\\left(p^*, e_1, \\ldots, e_k\\right)\n",
    "-\n",
    "\\lambda_{\\text{len}} \\, k\n",
    "-\n",
    "\\lambda_{\\text{div}} \\, R_{\\text{div}}(E)\n",
    "$$\n",
    "\n",
    "$$\n",
    "With: R_{\\text{div}}(E)\n",
    "=\n",
    "\\frac{1}{k(k-1)}\n",
    "\\sum_{i \\ne j}\n",
    "\\operatorname{sim}(e_i, e_j)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366b1e7",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- $p^*$ : Optimized instruction prompt.\n",
    "- $E = \\{e_1, \\ldots, e_k\\}$ : Set of selected exemplars.\n",
    "- $e_i$ : The $i$-th exemplar.\n",
    "- $k = |E|$ : Number of exemplars in the prompt.\n",
    "\n",
    "- $m(p^*, e_1, \\ldots, e_k)$ :\n",
    "  Task performance metric (e.g., accuracy, log-likelihood, reward)\n",
    "  when using instruction $p^*$ together with exemplars $E$.\n",
    "\n",
    "- $\\lambda_{\\mathrm{len}}$ :\n",
    "  Length regularization coefficient penalizing large exemplar sets.\n",
    "\n",
    "- $\\lambda_{\\mathrm{div}}$ :\n",
    "  Diversity regularization coefficient.\n",
    "\n",
    "- $\\mathrm{sim}(e_i, e_j)$ :\n",
    "  Similarity function between exemplars\n",
    "  (e.g., cosine similarity of embeddings).\n",
    "\n",
    "- $R_{\\mathrm{div}}(E)$ :\n",
    "  Average pairwise similarity among exemplars,\n",
    "  encouraging diversity and reducing overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5b5f4",
   "metadata": {},
   "source": [
    "---\n",
    "We optimize this objective using a genetic algorithm, where each individual represents a candidate exemplar set. Genetic operators such as selection, and mutation are applied to evolve exemplar populations toward higher objective scores. This formulation enables effective exploration of the combinatorial exemplar space while explicitly balancing performance, prompt length, and exemplar diversity."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
