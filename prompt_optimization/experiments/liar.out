{"task": "liar", "data_dir": "data/liar", "prompts": "prompts/liar.md", "out": "experiments/liar.out", "max_threads": 32, "temperature": 0.0, "optimizer": "nl-gradient", "rounds": 6, "beam_size": 4, "n_test_exs": 400, "minibatch_size": 256, "n_gradients": 4, "errors_per_gradient": 8, "gradients_per_error": 5, "steps_per_gradient": 1, "mc_samples_per_step": 4, "max_expansion_factor": 8, "engine": "chatgpt", "evaluator": "bf", "scorer": "01", "eval_rounds": 8, "eval_prompts_per_round": 8, "samples_per_eval": 32, "c": 1.0, "knn_k": 2, "knn_t": 0.993, "reject_on_errors": false, "reflect_gradients": false, "reflect_candidates": false, "reflection_candidate_threshold": 0.5, "reflection_gradient_passes": 1, "reflection_candidate_passes": 1, "reflection_temperature": 0.0, "ea_samples_per_step": 4, "eval_budget": 2048}
======== ROUND 0
Time: 3.1948089599609375e-05
Prompt: ("# Task\nEvaluate the truthfulness of the Statement by considering the Context, Job Title, State, Party Affiliation, and any other pertinent details. Assess the reliability of the speaker, the likelihood of the statement being true, and its potential political impact. If the statement is consistent with verified information or has backing from reliable sources, mark it as 'No'. If the statement is false or appears to be politically driven without substantiation, mark it as 'Yes'.\n# Exemplar\nExample goes here\n\n# Output format\nAnswer ONLY Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:",)
Training accuracy: (1.0,)
Validation accuracy: [0.6558265582655827]
Test accuracy: [0.6420824295010846]
