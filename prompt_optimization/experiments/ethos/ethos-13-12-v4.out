{"task": "ethos", "data_dir": "data/ethos", "prompts": "prompts/ethos.md", "out": "experiments/ethos.out", "max_threads": 32, "temperature": 0.0, "optimizer": "nl-gradient", "rounds": 6, "beam_size": 4, "n_test_exs": 400, "minibatch_size": 64, "n_gradients": 4, "errors_per_gradient": 4, "gradients_per_error": 1, "steps_per_gradient": 1, "mc_samples_per_step": 4, "max_expansion_factor": 8, "engine": "chatgpt", "evaluator": "bf", "scorer": "01", "eval_rounds": 8, "eval_prompts_per_round": 8, "samples_per_eval": 32, "c": 1.0, "knn_k": 2, "knn_t": 0.993, "reject_on_errors": true, "reflect_gradients": false, "reflect_candidates": false, "reflection_candidate_threshold": 0.5, "reflection_gradient_passes": 1, "reflection_candidate_passes": 1, "reflection_temperature": 0.0, "ea_samples_per_step": 4, "eval_budget": 2048}
======== ROUND 0
Time: 2.109781265258789
Prompt: ('# Task\nIs the following text hate speech?\n\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:',)
Training accuracy: (np.float64(0.83),)
Test accuracy: [0.8266666666666667]
======== ROUND 1
Time: 61.88919115066528
Prompt: ('# Task\n**Revised Instruction:**  \n\nDetermine whether the following text should be labeled as "Yes" or "No" for containing hate speech. For the purposes of this determination, hate speech is defined as any language that:\n\n- Demonstrates prejudice, hostility, or disdain toward an individual or group based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- Advocates for violence, discrimination, or harm against individuals or groups.\n- Employs language that dehumanizes or derogates others.\n- Supports or endorses oppressive systems or ideologies.\n\nApply these standards to assess whether the text qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nInstruction Variation: Determine whether the given text should be labeled as "Yes" or "No" for containing hate speech. For this determination, consider the following definitions of hate speech:\n\n- Language that shows prejudice, hostility, or disdain toward an individual or group based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected characteristics.\n- Statements that promote violence, discrimination, or harm against individuals or groups.\n- Use of language that dehumanizes or insults in a derogatory manner.\n- Support or advocacy for oppressive systems or ideologies.\n\nApply these guidelines to assess if the text qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDetermine whether the provided text falls under the category of "Hate Speech" or "Not Hate Speech." Assess if the text includes explicit or implicit expressions of prejudice, hostility, or dehumanization targeting attributes such as race, ethnicity, religion, gender, sexual orientation, disability, or other protected characteristics. Exercise care in interpreting sarcasm, hyperbole, or strong opinions that may not have the intent to cause harm or issue a threat.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nSure! Here\'s a variation of the instruction with the same semantic meaning:\n\n**Input:** Determine whether the given text should be labeled "Yes" if it includes hate speech, or "No" if it does not. Hate speech refers to expressions that target or dehumanize individuals or groups based on characteristics like race, religion, ethnicity, national origin, gender, sexual orientation, disability, or other protected attributes. This includes threats, offensive language, slurs, and calls for violence or discrimination. Be sure to take into account the speaker\'s intent and the surrounding context when making your judgment.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:')
Training accuracy: (np.float64(0.89), np.float64(0.89), np.float64(0.87), np.float64(0.86))
Test accuracy: [0.88, 0.9066666666666666, 0.88, 0.88]
======== ROUND 2
Time: 662.7152211666107
Prompt: ('# Task\n**Revised Instruction (Variation):**\n\nDecide whether the following text should be classified as "Yes" or "No" for containing hate speech. For the purpose of this classification, **hate speech is defined as content that meets one or more of the following conditions:**\n\n- **Clearly** conveys prejudice, hostility, or contempt toward an individual or group based on characteristics such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** employs language that dehumanizes or belittles individuals in a manner that is specifically targeted at a protected group.\n- **Clearly** promotes or backs oppressive systems or ideologies.\n\n**Important Note:** General insults, sarcasm, or offensive language that is not clearly connected to protected categories or systemic oppression should be labeled "No." The text must unambiguously show an intent to harm or devalue based on protected attributes or explicitly support harmful or oppressive actions.\n\nUse these guidelines to evaluate whether the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction:**\n\nDecide whether the provided text should be classified as "Yes" or "No" for containing hate speech. For this classification, **hate speech is defined as content that meets at least one of the following conditions:**\n\n- **Clearly** conveys prejudice, hostility, or contempt toward an individual or group based on characteristics such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** employs dehumanizing or derogatory language that is specifically aimed at a protected group.\n- **Clearly** promotes or aligns with oppressive systems or ideologies.\n\n**Note:** General insults, sarcastic remarks, or offensive language that is not directly linked to protected categories or systemic oppression should be labeled "No." The text must unambiguously show intent to cause harm or devalue individuals or groups based on protected attributes, or explicitly support harmful actions.\n\nUse these guidelines to determine if the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction:**\n\nDetermine whether the following text should be labeled as "Yes" or "No" for containing hate speech. For the purposes of this determination, **hate speech must meet one or more of the following criteria:**\n\n- **Explicitly** expresses prejudice, hostility, or disdain toward an individual or group based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Explicitly** advocates for violence, discrimination, or harm against individuals or groups.\n- **Explicitly** uses language that dehumanizes or derogates others in a way that is clearly targeted at a protected group.\n- **Explicitly** supports or endorses oppressive systems or ideologies.\n\n**Important:** General insults, sarcasm, or offensive language not clearly tied to protected categories or systemic oppression should be labeled "No." The text must clearly demonstrate intent to harm or devalue based on protected attributes or explicitly support oppressive actions.\n\nApply these standards to assess whether the text qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Improved Version):**\n\nClassify the following text as "Yes" if it contains hate speech, and "No" otherwise. For the purposes of this classification, hate speech is defined as text that:\n\n- **Directly attacks or dehumanizes** individuals or groups based on race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Advocates for violence, discrimination, or harm** against individuals or groups based on these attributes.\n- Uses **derogatory or slurs** targeting protected groups.\n- **Explicitly supports oppressive systems or ideologies** that target protected groups.\n\n**Do not label as hate speech**:\n- General expressions of dislike, sarcasm, or satire that are not directed at protected groups.\n- Hyperbolic or metaphorical language that does not clearly target individuals or groups based on protected attributes.\n- Criticism of policies or actions, even if harsh, unless it explicitly promotes violence, discrimination, or harm.\n\nApply these guidelines to determine whether the text qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:')
Training accuracy: (np.float64(0.92), np.float64(0.92), np.float64(0.92), np.float64(0.9))
Test accuracy: [0.8733333333333333, 0.88, 0.8733333333333333, 0.8933333333333333]
======== ROUND 3
Time: 1019.2076416015625
Prompt: ('# Task\n**Revised Instruction (Variation):**\n\nDecide whether the following text should be classified as "Yes" or "No" for containing hate speech. For the purpose of this classification, **hate speech is defined as content that meets one or more of the following conditions:**\n\n- **Clearly** conveys prejudice, hostility, or contempt toward an individual or group based on characteristics such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** employs language that dehumanizes or belittles individuals in a manner that is specifically targeted at a protected group.\n- **Clearly** promotes or backs oppressive systems or ideologies.\n\n**Important Note:** General insults, sarcasm, or offensive language that is not clearly connected to protected categories or systemic oppression should be labeled "No." The text must unambiguously show an intent to harm or devalue based on protected attributes or explicitly support harmful or oppressive actions.\n\nUse these guidelines to evaluate whether the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction:**\n\nDecide whether the provided text should be classified as "Yes" or "No" for containing hate speech. For this classification, **hate speech is defined as content that meets at least one of the following conditions:**\n\n- **Clearly** conveys prejudice, hostility, or contempt toward an individual or group based on characteristics such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** employs dehumanizing or derogatory language that is specifically aimed at a protected group.\n- **Clearly** promotes or aligns with oppressive systems or ideologies.\n\n**Note:** General insults, sarcastic remarks, or offensive language that is not directly linked to protected categories or systemic oppression should be labeled "No." The text must unambiguously show intent to cause harm or devalue individuals or groups based on protected attributes, or explicitly support harmful actions.\n\nUse these guidelines to determine if the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction:**\n\nDetermine whether the following text should be labeled as "Yes" or "No" for containing hate speech. For the purposes of this determination, **hate speech must meet one or more of the following criteria:**\n\n- **Explicitly** expresses prejudice, hostility, or disdain toward an individual or group based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Explicitly** advocates for violence, discrimination, or harm against individuals or groups.\n- **Explicitly** uses language that dehumanizes or derogates others in a way that is clearly targeted at a protected group.\n- **Explicitly** supports or endorses oppressive systems or ideologies.\n\n**Important:** General insults, sarcasm, or offensive language not clearly tied to protected categories or systemic oppression should be labeled "No." The text must clearly demonstrate intent to harm or devalue based on protected attributes or explicitly support oppressive actions.\n\nApply these standards to assess whether the text qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Variation):**\n\nAssess whether the given text should be classified as "Yes" or "No" for containing hate speech. For the purpose of this evaluation, **hate speech is understood as any communication that:**\n\n- **Directly or indirectly** conveys prejudice, hostility, or contempt toward an individual or group based on characteristics such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Directly or indirectly** promotes violence, discrimination, or harm against individuals or groups.\n- **Directly or indirectly** employs language that dehumanizes or derogates others in a manner that is clearly aimed at a protected group.\n- **Directly or indirectly** promotes or condones oppressive systems or ideologies.\n\n**Important Note:** The language does not need to be severe or explicitly violent. Consider **context, tone, and intent** in your analysis. General insults, sarcasm, or offensive language that is not clearly linked to protected categories or systemic oppression should be labeled "No." The text must show **some level of targeted hostility, dehumanization, or support for oppressive actions**, whether clearly stated or suggested through context or tone.\n\nUse these guidelines to determine if the text meets the criteria for hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:')
Training accuracy: (np.float64(0.92), np.float64(0.92), np.float64(0.92), np.float64(0.92))
Test accuracy: [0.8733333333333333, 0.88, 0.8666666666666667, 0.8466666666666667]
======== ROUND 4
Time: 574.0277154445648
Prompt: ('# Task\n**Revised Prompt:**\n\nClassify the provided text as "Yes" or "No" for containing hate speech. Hate speech is defined as content that **clearly and explicitly** meets **at least one of the following conditions**:\n\n- **Clearly** expresses prejudice, hostility, or contempt toward an individual or group based on race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** uses dehumanizing or derogatory language that is specifically and directly aimed at a protected group.\n- **Clearly** promotes or aligns with oppressive systems or ideologies.\n\n**Important:**  \n- General insults, sarcastic remarks, or offensive language that is not clearly tied to protected categories or systemic oppression should be labeled "No."\n- Indirect criticism, hyperbolic expressions, or statements that do not clearly express intent to harm or devalue individuals or groups should also be labeled "No."\n- The text must **unambiguously** show intent to cause harm or devalue individuals or groups based on protected attributes, or explicitly support harmful actions.\n\nUse these guidelines to determine if the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Alternative Version):**\n\nAssess whether the provided text should be categorized as "Yes" or "No" for containing hate speech. For this classification, **hate speech is understood as text that:**\n\n1. **Explicitly or implicitly** conveys hostility, bias, or disdain toward a **protected group** (such as those defined by race, religion, ethnicity, gender, sexual orientation, disability, or other analogous traits).  \n2. **Explicitly or implicitly** advocates for violence, discrimination, or harm **aimed at a particular group**.  \n3. **Explicitly or implicitly** dehumanizes or belittles a specific group **in a manner that is unmistakably connected to systemic oppression or protected identities**.  \n4. **Explicitly or implicitly** supports or justifies **oppressive systems or ideologies** that are focused on specific groups.\n\n**Key Considerations:**\n- **General insults, sarcasm, or emotionally charged language that is not clearly aimed at a protected group** should be marked as "No."\n- **Hypothetical or conditional expressions** (e.g., "If they did X, I would do Y") should be judged based on whether a **protected group is clearly referenced** and whether the **language promotes hate or oppression.**\n- **Text that criticizes policies or behaviors without directly targeting a protected group** (e.g., "I dislike the policy, not the people") should be labeled "No."\n- **Strong or harsh language by itself is not enough** to classify as hate speech unless it is **clearly associated with a protected category or oppressive ideology.**\n\nApply these guidelines thoroughly to **evaluate the text** and determine if it qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Prompt:**\n\nYou are to determine whether the provided text contains hate speech by labeling it as "Yes" or "No." Apply the following **clear and strict criteria** for identifying hate speech:\n\n- **Hate speech** occurs when a communication:\n  - **Directly or indirectly** conveys **prejudice, hostility, or contempt** toward an individual or group based on **protected attributes** such as race, religion, ethnicity, gender, sexual orientation, disability, and similar categories.\n  - **Directly or indirectly** encourages **violence, discrimination, or harm** against individuals or groups.\n  - **Directly or indirectly** **dehumanizes or belittles** individuals or groups in a **clearly targeted** way.\n  - **Directly or indirectly** **supports or justifies oppressive systems or ideologies**.\n\n**Key Considerations:**\n- The communication must be **specifically directed at a particular group or individual**, not merely general offensive language or insults.\n- **Generic insults, sarcasm, or offensive expressions** that do not clearly tie to a **protected category or oppressive ideology** should be classified as "No."\n- **Context, tone, and intent** are essential. Even if the text includes terms like "racist," "genocide," "deport," or "asylum," it should only be considered hate speech if it **clearly targets a protected group or advocates for harm**.\n- **Avoid over-classification.** Reserve the "Yes" label only when the text unambiguously satisfies the criteria outlined above.\n\nUsing these guidelines, assess the text and provide your classification as either "Yes" or "No."\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Variation):**\n\nDetermine whether the given text should be categorized as "Yes" or "No" for containing hate speech. For the purposes of this classification, **hate speech is defined as any content that fulfills one or more of the following criteria:**\n\n- **Clearly** expresses prejudice, hostility, or disdain toward an individual or group based on attributes such as race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** advocates for violence, discrimination, or harm against individuals or groups.\n- **Clearly** uses language that dehumanizes or diminishes individuals in a way that is specifically aimed at a protected group.\n- **Clearly** supports or endorses oppressive systems or ideologies.\n\n**Important Note:** General insults, sarcastic remarks, or offensive language that is not clearly tied to protected categories or systemic oppression should be labeled "No." The text must unambiguously demonstrate an intent to cause harm or devalue based on protected attributes or explicitly endorse harmful or oppressive actions.\n\nApply these guidelines to assess whether the text qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:')
Training accuracy: (np.float64(0.92), np.float64(0.92), np.float64(0.92), np.float64(0.92))
Test accuracy: [0.8666666666666667, 0.88, 0.8533333333333334, 0.8666666666666667]
======== ROUND 5
Time: 1202.2964057922363
Prompt: ('# Task\n**Revised Prompt:**\n\nYou are to evaluate whether the given text constitutes hate speech by classifying it as either "Yes" or "No." Use the following **clear and strict guidelines** to make your determination:\n\n- **Hate speech** is present when a message:\n  - **Explicitly or implicitly** expresses **prejudice, hostility, or disdain** toward an individual or group based on **protected characteristics** such as race, religion, ethnicity, gender, sexual orientation, disability, and related categories.\n  - **Explicitly or implicitly** promotes **violence, discrimination, or harm** toward individuals or groups.\n  - **Explicitly or implicitly** **dehumanizes or diminishes** individuals or groups in a **clearly directed** manner.\n  - **Explicitly or implicitly** **supports or defends oppressive systems or ideologies**.\n\n**Important Factors to Consider:**\n- The message must **specifically target a group or individual**, even if the group is not directly named or is referenced through **coded, indirect, or symbolic** language.\n- **Sarcasm, irony, or veiled expressions** that suggest hostility or contempt toward a protected group should be considered hate speech when the **intent is unmistakable**.\n- **Context, tone, and intent** play a critical role. Terms such as "racist," "genocide," "deport," or "asylum" should only be classified as hate speech if they **clearly aim at a protected group or advocate for harm**.\n- **Avoid under-classification.** Be alert to **subtle or indirect expressions** that still meet the criteria for hate speech, particularly when they are directed at protected groups.\n- **Avoid over-classification.** Only label the text as "Yes" if it **unequivocally meets** the outlined criteria.\n\nBased on these standards, evaluate the text and provide your classification as either "Yes" or "No."\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Prompt:**\n\nClassify the provided text as "Yes" or "No" for containing hate speech. Hate speech is defined as content that **clearly and explicitly** meets **at least one of the following conditions**:\n\n- **Clearly** expresses prejudice, hostility, or contempt toward an individual or group based on race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** uses dehumanizing or derogatory language that is specifically and directly aimed at a protected group.\n- **Clearly** promotes or aligns with oppressive systems or ideologies.\n\n**Important:**  \n- General insults, sarcastic remarks, or offensive language that is not clearly tied to protected categories or systemic oppression should be labeled "No."\n- Indirect criticism, hyperbolic expressions, or statements that do not clearly express intent to harm or devalue individuals or groups should also be labeled "No."\n- The text must **unambiguously** show intent to cause harm or devalue individuals or groups based on protected attributes, or explicitly support harmful actions.\n\nUse these guidelines to determine if the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Alternative Version):**\n\nAssess whether the provided text should be categorized as "Yes" or "No" for containing hate speech. For this classification, **hate speech is understood as text that:**\n\n1. **Explicitly or implicitly** conveys hostility, bias, or disdain toward a **protected group** (such as those defined by race, religion, ethnicity, gender, sexual orientation, disability, or other analogous traits).  \n2. **Explicitly or implicitly** advocates for violence, discrimination, or harm **aimed at a particular group**.  \n3. **Explicitly or implicitly** dehumanizes or belittles a specific group **in a manner that is unmistakably connected to systemic oppression or protected identities**.  \n4. **Explicitly or implicitly** supports or justifies **oppressive systems or ideologies** that are focused on specific groups.\n\n**Key Considerations:**\n- **General insults, sarcasm, or emotionally charged language that is not clearly aimed at a protected group** should be marked as "No."\n- **Hypothetical or conditional expressions** (e.g., "If they did X, I would do Y") should be judged based on whether a **protected group is clearly referenced** and whether the **language promotes hate or oppression.**\n- **Text that criticizes policies or behaviors without directly targeting a protected group** (e.g., "I dislike the policy, not the people") should be labeled "No."\n- **Strong or harsh language by itself is not enough** to classify as hate speech unless it is **clearly associated with a protected category or oppressive ideology.**\n\nApply these guidelines thoroughly to **evaluate the text** and determine if it qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Improved Prompt):**\n\nYou are to determine whether the provided text qualifies as **hate speech** by classifying it as **"Yes"** or **"No"**. Use the following guidelines to make your assessment:\n\n**Hate speech is defined as text that:**\n\n1. **Explicitly or implicitly** expresses hostility, bias, or disdain toward a **protected group** (such as those defined by race, religion, ethnicity, gender, sexual orientation, disability, or other analogous traits).\n2. **Explicitly or implicitly** promotes or advocates for **violence, discrimination, or harm** directed at a **specific protected group**.\n3. **Explicitly or implicitly** dehumanizes or belittles a **protected group** in a way that is **clearly tied to systemic oppression or harmful ideology**.\n4. **Explicitly or implicitly** supports or justifies **oppressive systems or ideologies** that target specific protected groups.\n\n**Important Clarifications:**\n\n- **General insults, sarcasm, or emotionally charged language** that **does not clearly target a protected group** should be marked as **"No"**.\n- **Hypothetical or conditional statements** (e.g., "If they did X, I would do Y") should be judged based on whether a **protected group is clearly referenced** and whether the language promotes **hate or oppression**.\n- **Criticism of policies, behaviors, or actions** without a direct **reference to a protected group** (e.g., "I dislike the policy, not the people") should be marked as **"No"**.\n- **Strong or harsh language alone is not sufficient** to label as hate speech unless it is **clearly associated with a protected group or oppressive ideology**.\n- **Satire, parody, or expressions of personal dislike** (e.g., disliking a holiday, a team, or a celebrity) do **not** constitute hate speech unless they target a **protected group** with **dehumanizing or oppressive language**.\n\nUse these criteria to **carefully analyze the text** and determine whether it qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:')
Training accuracy: (np.float64(0.93), np.float64(0.92), np.float64(0.92), np.float64(0.92))
Test accuracy: [0.86, 0.86, 0.88, 0.8733333333333333]
======== ROUND 6
Time: 1164.7124681472778
Prompt: ('# Task\n**Revised Prompt:**\n\nYou are to determine whether the provided text qualifies as hate speech by categorizing it as either "Yes" or "No." Make your judgment using the **following clear and strict criteria**:\n\n- **Hate speech** exists when a message:\n  - **Explicitly or implicitly** conveys **prejudice, hostility, or contempt** toward an individual or group based on **protected attributes** such as race, religion, ethnicity, gender, sexual orientation, disability, and similar categories.\n  - **Explicitly or implicitly** advocates for **violence, discrimination, or harm** against individuals or groups.\n  - **Explicitly or implicitly** **dehumanizes or belittles** individuals or groups in a **clearly directed** way.\n  - **Explicitly or implicitly** **supports or justifies oppressive systems or ideologies**.\n\n- **Key Considerations:**\n  - The message must **specifically reference a group or individual**, even if the group is not directly named or is alluded to via **coded, indirect, or symbolic** language.\n  - **Sarcasm, irony, or cryptic expressions** that imply hostility or disdain toward a protected group should be considered hate speech **only when the intent is unambiguous** and the target is clearly a protected group.\n  - **Context, tone, and intent** are essential. Words such as "racist," "genocide," "deport," or "asylum" should only be classified as hate speech if they **clearly point to a protected group or suggest advocating for harm**.\n  - **Avoid under-classification.** Be watchful for **subtle or indirect expressions** that still meet the hate speech criteria, especially when they are directed at protected groups.\n  - **Avoid over-classification.** Only assign the label "Yes" if the text **clearly and unambiguously meets** the outlined criteria — **even if the language is strong**, the **target must be clear** and the **intent must be hostile** toward a protected group.\n\n**Examples to guide your classification:**\n- "Slaughter on a weekly basis, very racist are the Israelis to the point of genocide." — **Label: No (criticizes actions, not a protected group directly)**.\n- "Deport him in military aircraft and dump him back where he is originated from." — **Label: No (targets an individual, not a protected group)**.\n- "Easter is the most silly holiday ever existed. It must be stopped. Shame shame shame." — **Label: Yes (targets a religious group with dehumanizing language)**.\n- "To the lady that can barely speak English and then look down upon her own people, that\'s disgraceful." — **Label: No (criticizes behavior, not a protected group)**.\n\nUsing these guidelines, assess the text and provide your classification as either "Yes" or "No."\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Prompt:**\n\nYou are to evaluate whether the given text constitutes hate speech by classifying it as either "Yes" or "No." Use the following **clear and strict guidelines** to make your determination:\n\n- **Hate speech** is present when a message:\n  - **Explicitly or implicitly** expresses **prejudice, hostility, or disdain** toward an individual or group based on **protected characteristics** such as race, religion, ethnicity, gender, sexual orientation, disability, and related categories.\n  - **Explicitly or implicitly** promotes **violence, discrimination, or harm** toward individuals or groups.\n  - **Explicitly or implicitly** **dehumanizes or diminishes** individuals or groups in a **clearly directed** manner.\n  - **Explicitly or implicitly** **supports or defends oppressive systems or ideologies**.\n\n**Important Factors to Consider:**\n- The message must **specifically target a group or individual**, even if the group is not directly named or is referenced through **coded, indirect, or symbolic** language.\n- **Sarcasm, irony, or veiled expressions** that suggest hostility or contempt toward a protected group should be considered hate speech when the **intent is unmistakable**.\n- **Context, tone, and intent** play a critical role. Terms such as "racist," "genocide," "deport," or "asylum" should only be classified as hate speech if they **clearly aim at a protected group or advocate for harm**.\n- **Avoid under-classification.** Be alert to **subtle or indirect expressions** that still meet the criteria for hate speech, particularly when they are directed at protected groups.\n- **Avoid over-classification.** Only label the text as "Yes" if it **unequivocally meets** the outlined criteria.\n\nBased on these standards, evaluate the text and provide your classification as either "Yes" or "No."\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Prompt:**\n\nClassify the provided text as "Yes" or "No" for containing hate speech. Hate speech is defined as content that **clearly and explicitly** meets **at least one of the following conditions**:\n\n- **Clearly** expresses prejudice, hostility, or contempt toward an individual or group based on race, religion, ethnicity, gender, sexual orientation, disability, or other protected categories.\n- **Clearly** promotes violence, discrimination, or harm directed at individuals or groups.\n- **Clearly** uses dehumanizing or derogatory language that is specifically and directly aimed at a protected group.\n- **Clearly** promotes or aligns with oppressive systems or ideologies.\n\n**Important:**  \n- General insults, sarcastic remarks, or offensive language that is not clearly tied to protected categories or systemic oppression should be labeled "No."\n- Indirect criticism, hyperbolic expressions, or statements that do not clearly express intent to harm or devalue individuals or groups should also be labeled "No."\n- The text must **unambiguously** show intent to cause harm or devalue individuals or groups based on protected attributes, or explicitly support harmful actions.\n\nUse these guidelines to determine if the text constitutes hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\n**Revised Instruction (Alternative Version):**\n\nAssess whether the provided text should be categorized as "Yes" or "No" for containing hate speech. For this classification, **hate speech is understood as text that:**\n\n1. **Explicitly or implicitly** conveys hostility, bias, or disdain toward a **protected group** (such as those defined by race, religion, ethnicity, gender, sexual orientation, disability, or other analogous traits).  \n2. **Explicitly or implicitly** advocates for violence, discrimination, or harm **aimed at a particular group**.  \n3. **Explicitly or implicitly** dehumanizes or belittles a specific group **in a manner that is unmistakably connected to systemic oppression or protected identities**.  \n4. **Explicitly or implicitly** supports or justifies **oppressive systems or ideologies** that are focused on specific groups.\n\n**Key Considerations:**\n- **General insults, sarcasm, or emotionally charged language that is not clearly aimed at a protected group** should be marked as "No."\n- **Hypothetical or conditional expressions** (e.g., "If they did X, I would do Y") should be judged based on whether a **protected group is clearly referenced** and whether the **language promotes hate or oppression.**\n- **Text that criticizes policies or behaviors without directly targeting a protected group** (e.g., "I dislike the policy, not the people") should be labeled "No."\n- **Strong or harsh language by itself is not enough** to classify as hate speech unless it is **clearly associated with a protected category or oppressive ideology.**\n\nApply these guidelines thoroughly to **evaluate the text** and determine if it qualifies as hate speech.\n# Output format\nAnswer ONLY "Yes" or "No".\nNO explanations.\nNo other words.\n\n# Prediction\nText: {{ text }}\nLabel:')
Training accuracy: (np.float64(0.93), np.float64(0.93), np.float64(0.92), np.float64(0.92))
Test accuracy: [0.8466666666666667, 0.86, 0.8666666666666667, 0.88]
======== EXEMPLAR OPTIMIZATION ROUND 0
Time: 13.016737937927246
Prompt: # Task
**Revised Prompt:**

You are to determine whether the provided text qualifies as hate speech by categorizing it as either "Yes" or "No." Make your judgment using the **following clear and strict criteria**:

- **Hate speech** exists when a message:
- **Explicitly or implicitly** conveys **prejudice, hostility, or contempt** toward an individual or group based on **protected attributes** such as race, religion, ethnicity, gender, sexual orientation, disability, and similar categories.
- **Explicitly or implicitly** advocates for **violence, discrimination, or harm** against individuals or groups.
- **Explicitly or implicitly** **dehumanizes or belittles** individuals or groups in a **clearly directed** way.
- **Explicitly or implicitly** **supports or justifies oppressive systems or ideologies**.

- **Key Considerations:**
- The message must **specifically reference a group or individual**, even if the group is not directly named or is alluded to via **coded, indirect, or symbolic** language.
- **Sarcasm, irony, or cryptic expressions** that imply hostility or disdain toward a protected group should be considered hate speech **only when the intent is unambiguous** and the target is clearly a protected group.
- **Context, tone, and intent** are essential. Words such as "racist," "genocide," "deport," or "asylum" should only be classified as hate speech if they **clearly point to a protected group or suggest advocating for harm**.
- **Avoid under-classification.** Be watchful for **subtle or indirect expressions** that still meet the hate speech criteria, especially when they are directed at protected groups.
- **Avoid over-classification.** Only assign the label "Yes" if the text **clearly and unambiguously meets** the outlined criteria — **even if the language is strong**, the **target must be clear** and the **intent must be hostile** toward a protected group.

**Examples to guide your classification:**
- "Slaughter on a weekly basis, very racist are the Israelis to the point of genocide." — **Label: No (criticizes actions, not a protected group directly)**.
- "Deport him in military aircraft and dump him back where he is originated from." — **Label: No (targets an individual, not a protected group)**.
- "Easter is the most silly holiday ever existed. It must be stopped. Shame shame shame." — **Label: Yes (targets a religious group with dehumanizing language)**.
- "To the lady that can barely speak English and then look down upon her own people, that's disgraceful." — **Label: No (criticizes behavior, not a protected group)**.

Using these guidelines, assess the text and provide your classification as either "Yes" or "No."

# Exemplar
Text: Trace, I would ask you to rethink the out of Africa myth. Since the out of Africa theory was proposed, there have been many discoveries that prove modern humans existed in other parts of the world much earlier than what was thought when the OOA theory was proposed. For instance, there have been skeletal remains of humans found in Asia that are many thousands of years older than the oldest found on the African Content. It amazes me that there is so much information out there that shows older humans elsewhere on Earth but people still adhere to the falls narrative that modern humans evolved on the African continent
Label: No
Text: Indians are shit but burgers only have broken English and ebonics to learn and still fail. Second thread in a row where a burger can't figure out you're and your
Label: Yes
Text: Easter is the most silly holiday ever existed. It must be stopped. Shame shame shame
Label: Yes
# Output format
Answer ONLY "Yes" or "No".
NO explanations.
No other words.

# Prediction
Text: {{ text }}
Label:
Training accuracy: 0.94
Test accuracy: 0.8866666666666667
======== EXEMPLAR OPTIMIZATION ROUND 1
Time: 5.006737947463989
Prompt: # Task
**Revised Prompt:**

You are to determine whether the provided text qualifies as hate speech by categorizing it as either "Yes" or "No." Make your judgment using the **following clear and strict criteria**:

- **Hate speech** exists when a message:
- **Explicitly or implicitly** conveys **prejudice, hostility, or contempt** toward an individual or group based on **protected attributes** such as race, religion, ethnicity, gender, sexual orientation, disability, and similar categories.
- **Explicitly or implicitly** advocates for **violence, discrimination, or harm** against individuals or groups.
- **Explicitly or implicitly** **dehumanizes or belittles** individuals or groups in a **clearly directed** way.
- **Explicitly or implicitly** **supports or justifies oppressive systems or ideologies**.

- **Key Considerations:**
- The message must **specifically reference a group or individual**, even if the group is not directly named or is alluded to via **coded, indirect, or symbolic** language.
- **Sarcasm, irony, or cryptic expressions** that imply hostility or disdain toward a protected group should be considered hate speech **only when the intent is unambiguous** and the target is clearly a protected group.
- **Context, tone, and intent** are essential. Words such as "racist," "genocide," "deport," or "asylum" should only be classified as hate speech if they **clearly point to a protected group or suggest advocating for harm**.
- **Avoid under-classification.** Be watchful for **subtle or indirect expressions** that still meet the hate speech criteria, especially when they are directed at protected groups.
- **Avoid over-classification.** Only assign the label "Yes" if the text **clearly and unambiguously meets** the outlined criteria — **even if the language is strong**, the **target must be clear** and the **intent must be hostile** toward a protected group.

**Examples to guide your classification:**
- "Slaughter on a weekly basis, very racist are the Israelis to the point of genocide." — **Label: No (criticizes actions, not a protected group directly)**.
- "Deport him in military aircraft and dump him back where he is originated from." — **Label: No (targets an individual, not a protected group)**.
- "Easter is the most silly holiday ever existed. It must be stopped. Shame shame shame." — **Label: Yes (targets a religious group with dehumanizing language)**.
- "To the lady that can barely speak English and then look down upon her own people, that's disgraceful." — **Label: No (criticizes behavior, not a protected group)**.

Using these guidelines, assess the text and provide your classification as either "Yes" or "No."

# Exemplar
Text: We have to take our power back as the superior gender. 
Label: Yes
Text: I'm sick and tired of this black and white thing....can't we just stop and let's be happy for just one day.....we are all one let's stop this please... One love and peace.
Label: No
Text: fat bitch....she need that black cucumber up her tight u know what....lmfaooo
Label: Yes
# Output format
Answer ONLY "Yes" or "No".
NO explanations.
No other words.

# Prediction
Text: {{ text }}
Label:
Training accuracy: 0.96
Test accuracy: 0.88
======== EXEMPLAR OPTIMIZATION ROUND 2
Time: 6.504736423492432
Prompt: # Task
**Revised Prompt:**

You are to determine whether the provided text qualifies as hate speech by categorizing it as either "Yes" or "No." Make your judgment using the **following clear and strict criteria**:

- **Hate speech** exists when a message:
- **Explicitly or implicitly** conveys **prejudice, hostility, or contempt** toward an individual or group based on **protected attributes** such as race, religion, ethnicity, gender, sexual orientation, disability, and similar categories.
- **Explicitly or implicitly** advocates for **violence, discrimination, or harm** against individuals or groups.
- **Explicitly or implicitly** **dehumanizes or belittles** individuals or groups in a **clearly directed** way.
- **Explicitly or implicitly** **supports or justifies oppressive systems or ideologies**.

- **Key Considerations:**
- The message must **specifically reference a group or individual**, even if the group is not directly named or is alluded to via **coded, indirect, or symbolic** language.
- **Sarcasm, irony, or cryptic expressions** that imply hostility or disdain toward a protected group should be considered hate speech **only when the intent is unambiguous** and the target is clearly a protected group.
- **Context, tone, and intent** are essential. Words such as "racist," "genocide," "deport," or "asylum" should only be classified as hate speech if they **clearly point to a protected group or suggest advocating for harm**.
- **Avoid under-classification.** Be watchful for **subtle or indirect expressions** that still meet the hate speech criteria, especially when they are directed at protected groups.
- **Avoid over-classification.** Only assign the label "Yes" if the text **clearly and unambiguously meets** the outlined criteria — **even if the language is strong**, the **target must be clear** and the **intent must be hostile** toward a protected group.

**Examples to guide your classification:**
- "Slaughter on a weekly basis, very racist are the Israelis to the point of genocide." — **Label: No (criticizes actions, not a protected group directly)**.
- "Deport him in military aircraft and dump him back where he is originated from." — **Label: No (targets an individual, not a protected group)**.
- "Easter is the most silly holiday ever existed. It must be stopped. Shame shame shame." — **Label: Yes (targets a religious group with dehumanizing language)**.
- "To the lady that can barely speak English and then look down upon her own people, that's disgraceful." — **Label: No (criticizes behavior, not a protected group)**.

Using these guidelines, assess the text and provide your classification as either "Yes" or "No."

# Exemplar
Text: We have to take our power back as the superior gender. 
Label: Yes
Text: I'm sick and tired of this black and white thing....can't we just stop and let's be happy for just one day.....we are all one let's stop this please... One love and peace.
Label: No
Text: fat bitch....she need that black cucumber up her tight u know what....lmfaooo
Label: Yes
# Output format
Answer ONLY "Yes" or "No".
NO explanations.
No other words.

# Prediction
Text: {{ text }}
Label:
Training accuracy: 0.96
Test accuracy: 0.88
